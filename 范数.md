# 范数
复杂空间多维元素的度量方法(矩阵，向量)

## 1范数
* 向量：$||X||_1 =  \sum\limits_{i=1}^n|x_i|$各元素的绝对值之和
* 矩阵：$||A||_1 = \underset {1 \le j \le n}{max}\sum\limits_{i=1}^n|a_{ij}|$即所有列绝对值之和的最大值，也叫列模
## 2范数
* 向量：$||X||_2 =  \sqrt{\sum\limits_{i=1}^nx_i^2}$各元素的平方之和再开根号
* $||A||_2 = \sqrt{\lambda_{max}(A^TA)}$即A的最大特征值开根号 
## 无穷范数
* 向量：
  * 正无穷范数 $max|x_i|$绝对值最大的元素
  * 负无穷范数 $min|x_i|$绝对值最小的元素
* 矩阵：$||A||_1 = \underset {1 \le i \le n}{max}\sum\limits_{j=1}^n|a_{ij}|$即所有行绝对值之和的最大值，也叫行模
# 机器学习中常见的其他特殊范数
一般都是指矩阵的范数，向量的这些概念是不变的，即1范数与L1范数相同，而矩阵则是不一样的
## L0范数
$||A||_{L0} = count(a_{ij} \neq 0)$矩阵A的非零元素个数，衡量一个矩阵的稀疏性
## L1范数
$||A||_{L1} = \sum |a_{ij}|$矩阵各元素的绝对值之和,是L0范数的最优凸近似，也可以近似反映稀疏性
## F范数(L2范数) 
$||A||_{L2} = \sqrt {\sum |a_{ij}^2|}$矩阵各元素的平方和开根号，是凸函数，有导数
## 核范数
核范数是矩阵的奇异值之和，即$\sum svd(A)$，最小化核范数相当于最小化矩阵的秩