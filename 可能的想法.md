* 区域位置编码，代码的特性是区域强相关，例如一个方法中的几行，一个类中的几行都是相关联的。联想一下，对于神经网络来说，实际上是模拟一个关于输入x的函数F,每次要得到输出y。那么对于位置信息也是一个输入，那么可以写作， y = F(x, p)。对于现有的几个位置编码来说，即将输入序列与位置相加，或者相乘，那么可以写作， y = F(x,p), F = x + p 或  y = F(x,p), F = x * p。这种直觉上的方式可能限制了模型学习输入序列和位置的关系。那么F能不能够使用神经网络来模拟。那么，损失函数如何定义，ground truth是什么。
* 基于NBCE扩展模型的输入长度，而后对每个输入的语言块选出代表语句，然后在代表语句之间进行attention计算。
* 有文章将代码生成建模为马尔科夫过程，但是实际上人类编写代码的过程中不一定符合马尔科夫过程，或者说马尔科夫过程的假设太强。
* 如果把强化学习引入代码生成任务的话，那么参考alphaGo，棋类游戏的奖励函数到整个棋局结束后才能计算。而代码里可以分为两部分，一部分即时奖励，主要是对写出符合语法的代码的奖励，另一部分为长时奖励，主要是对通过测试用例的奖励。
* 任务流生成，根据需求文档生成完整的业务代码可以分解为多个子任务，形成任务流。例如登录注册模块，大致分为，接收用户账号密码、查询数据库、验证正确性。同时这三个任务之间的代码有依赖性，设计到相互调用。首先，模型要会自己分解任务，其次模型要了解任务间的依赖，最后是写出正确代码通过测试。
* 如果attention能够分解成多个注意力头路径，那么能否用强化学习的方法在训练过程中控制token经过那个注意力路径
* 模块依赖分析，变量依赖分析，使得可以局部修改代码
* 尝试次数惩罚
* 构建工具环境，例如使得模型可以查询java文档，得到一些没有的知识，根据这个知识来进行下一步任务的完成。
* 一个参数量小但是专精推理任务的模型和一个大模型利用prompt做推理任务哪个更好?如果小模型更好，那能否利用小模型去引导大模型在某个任务上变成专家
* CoT、ReAct、Parsel等分解方法中间步骤为什么一定要用自然语言，能否直接用矩阵表示
* 段级自回归，即一次生成一段代码，后一段依赖前一段，可以将mcts搜索树变成非定长的，即每个树节点都可能是一段代码。
* 做一个软件开发任务的数据集
* 模型的评价能力没有人测试过，即他能否正确评价一段代码的好坏，或者一段文章的好坏，并基于此做出决策
* 根据LoRA进一步可以探索，不同的下游任务强调了哪些维度